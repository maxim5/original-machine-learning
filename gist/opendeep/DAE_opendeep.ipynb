{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports and logger!\n",
    "from opendeep.log import config_root_logger\n",
    "from opendeep.models import GSN\n",
    "from opendeep.optimization import SGD\n",
    "from opendeep.data import MNIST\n",
    "from opendeep.utils.misc import closest_to_square_factors\n",
    "from PIL import Image as pil_img\n",
    "from opendeep.utils.image import tile_raster_images\n",
    "import numpy\n",
    "\n",
    "config_root_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A denoising autoencoder (DAE) is a special case of a generative stochastic network (GSN).\n",
    "# GSN's can have multiple denoising layers that interact with each other both above and below.\n",
    "dae = GSN(\n",
    "    input_size=28*28,\n",
    "    hidden_size=1000,\n",
    "    visible_activation='sigmoid',\n",
    "    hidden_activation='tanh',\n",
    "    layers=1,\n",
    "    walkbacks=3,\n",
    "    input_noise='salt_and_pepper',\n",
    "    input_noise_level=0.3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the MNIST data object\n",
    "mnist = MNIST(concat_train_valid=True)\n",
    "\n",
    "# Create the optimizer object\n",
    "optimizer = SGD(dataset=mnist,\n",
    "                epochs=40, \n",
    "                batch_size=100, \n",
    "                learning_rate=.25,\n",
    "                lr_decay='exponential',\n",
    "                lr_decay_factor=.995,\n",
    "                momentum=.5,\n",
    "                nesterov_momentum=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the model with the optimizer on the mnist dataset!\n",
    "dae.train(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run some numbers to see the output\n",
    "n_examples = 100\n",
    "xs_test = mnist.test_inputs[:n_examples]\n",
    "noisy_xs_test = dae.f_noise(xs_test)\n",
    "reconstructed = dae.run(noisy_xs_test)\n",
    "# Concatenate stuff\n",
    "stacked = numpy.vstack(\n",
    "    [numpy.vstack([xs_test[i * 10: (i + 1) * 10],\n",
    "                   noisy_xs_test[i * 10: (i + 1) * 10],\n",
    "                   reconstructed[i * 10: (i + 1) * 10]])\n",
    "     for i in range(10)])\n",
    "number_reconstruction = pil_img.fromarray(\n",
    "    tile_raster_images(stacked, (dae.image_height, dae.image_width), (10, 30), (1, 1))\n",
    ")\n",
    "\n",
    "number_reconstruction.save(\"dae_opendeep_test.png\")\n",
    "\n",
    "# Construct image from the weight matrix\n",
    "image = pil_img.fromarray(\n",
    "    tile_raster_images(\n",
    "        X=dae.weights_list[0].get_value(borrow=True).T,\n",
    "        img_shape=(28, 28),\n",
    "        tile_shape=closest_to_square_factors(dae.layer_sizes[1]),\n",
    "        tile_spacing=(1, 1)\n",
    "    )\n",
    ")\n",
    "image.save(\"dae_opendeep_filters.png\")\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
